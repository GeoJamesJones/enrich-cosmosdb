{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import azure.cosmos.cosmos_client as cosmos_client\n",
    "\n",
    "from helpers import keys\n",
    "from helpers import nlp_helper\n",
    "from gremlin_python.driver import client, serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'ENDPOINT': keys.cosmos_uri,\n",
    "    'PRIMARYKEY': keys.cosmos_primary_key,\n",
    "    'DATABASE': 'NetOwl',\n",
    "    'CONTAINER': 'Entities',\n",
    "    'LINK-CONTAINER': 'Links',\n",
    "    'EVENT-CONTAINER': 'Events'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = r'C:\\Users\\jame9353\\Box Sync\\Data\\Early Bird'\n",
    "json_out_dir = r'C:\\Data\\json'\n",
    "geoevent_url = r'https://ge-1.eastus.cloudapp.azure.com:6143/geoevent/rest/receiver/netowl-geoentities-in'\n",
    "\n",
    "out_ext = \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to Cosmos DB Graph Client...\")\n",
    "graph_client = client.Client('wss://pilot-graph.gremlin.cosmosdb.azure.com:443/','g', \n",
    "        username=\"/dbs/NetOwl/colls/Links\", \n",
    "        password=\"whE1lJjFxzVSCQ7ppNDc5hMCwNl7x8C0BeMTF6dGq4pTN3c8qDVyUBLutYwQZJW1haxJP6W8wckzqBepDcGlAQ==\",\n",
    "        message_serializer=serializer.GraphSONMessageSerializer()\n",
    "    )\n",
    "print(\"Successfully connected to Cosmos DB Graph Client\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Cosmos client\n",
    "\n",
    "print(\"Connecting to Cosmos DB SQL API...\")\n",
    "client = cosmos_client.CosmosClient(url_connection=config['ENDPOINT'], auth={\n",
    "                                    'masterKey': config['PRIMARYKEY']})\n",
    "\n",
    "print(\"Creating Database...\")\n",
    "# Create a database\n",
    "db = client.CreateDatabase({'id': config['DATABASE']})\n",
    "\n",
    "# Create container options\n",
    "options = {\n",
    "    'offerThroughput': 400\n",
    "}\n",
    "\n",
    "container_definition = {\n",
    "    'id': config['CONTAINER']\n",
    "}\n",
    "\n",
    "link_container_definition = {\n",
    "    'id': config['LINK-CONTAINER']\n",
    "}\n",
    "\n",
    "event_container_definition = {\n",
    "    'id': config['EVENT-CONTAINER']\n",
    "}\n",
    "\n",
    "# Create a container for Entities\n",
    "print(\"Creating \" + str(config['CONTAINER']) + \" container...\")\n",
    "container = client.CreateContainer(db['_self'], container_definition, options)\n",
    "\n",
    "# Create a container for Links\n",
    "print(\"Creating \" + str(config['LINK-CONTAINER']) + \" container...\")\n",
    "link_container = client.CreateContainer(db['_self'], link_container_definition, options)\n",
    "\n",
    "# Create a container for Events\n",
    "print(\"Creating \" + str(config['EVENT-CONTAINER']) + \" container...\")\n",
    "event_container = client.CreateContainer(db['_self'], event_container_definition, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numchars = 100  # number of characters to retrieve for head/tail\n",
    "\n",
    "# Function to watch a folder and detect new images on a 1 second refresh interval\n",
    "#before = dict ([(f, None) for f in os.listdir (docs_path)])\n",
    "before = {}\n",
    "count = 0\n",
    "errors = 0\n",
    "\n",
    "print(\"Beginning monitor of \" + str(docs_path) + \" at \" + str(datetime.datetime.now()))\n",
    "\n",
    "while True:   \n",
    "    \n",
    "    # Compares the folder contents after the sleep to what existed beforehand, and makes a list of adds and removes\n",
    "    after = dict ([(f, None) for f in os.listdir (docs_path)])\n",
    "    added = [f for f in after if not f in before]\n",
    "    removed = [f for f in before if not f in after]\n",
    "\n",
    "    if added: print(\"Added: \", \", \".join (added))\n",
    "    if removed: print(\"Removed: \", \", \".join (removed))\n",
    "    before = after\n",
    "    \n",
    "    for filename in added:\n",
    "        if filename.endswith(\".htm\"):\n",
    "            print(\"Processing \" + filename + \" at \" + str(datetime.datetime.now()))\n",
    "            start = time.time()\n",
    "            \n",
    "            # create empty lists for objects\n",
    "            rdfobjs = []\n",
    "            rdfobjsGeo = []\n",
    "            linkobjs = []\n",
    "            eventobjs = []\n",
    "            orgdocs = []\n",
    "\n",
    "            haslinks = False\n",
    "            bigstring = \"\"  # keeps track of what was sent\n",
    "\n",
    "            newhead = \"\"  # empty string to catch empty head/tail\n",
    "            newtail = \"\"\n",
    "            \n",
    "            filepath = os.path.join(docs_path, filename)\n",
    "            nlp_helper.netowl_curl(filepath, json_out_dir, out_ext, keys.netowl_key)\n",
    "            outfile = os.path.join(json_out_dir, filename + out_ext)\n",
    "            \n",
    "            with open(outfile, 'r', encoding=\"utf-8\") as file:\n",
    "                rdfstring = json.load(file)\n",
    "                uniquets = str(time.time())  # unique time stamp for each doc\n",
    "                doc = rdfstring['document'][0]  # gets main part\n",
    "                \n",
    "                if 'text' in doc:\n",
    "                    v = doc['text'][0]\n",
    "                    if 'content' in v:\n",
    "                        bigstring = v['content']\n",
    "                \n",
    "                if 'entity' not in doc:\n",
    "                    print(\"ERROR: Nothing returned from NetOwl, or other unspecified error.\")  # NOQA E501\n",
    "                    break\n",
    "                    \n",
    "                ents = (doc['entity'])  # gets all entities in doc\n",
    "                \n",
    "                for e in ents:\n",
    "\n",
    "                    # gather data from each entity\n",
    "                    # rdfvalue = nof.cleanup_text(e['value'])  # value (ie name)\n",
    "                    rdfvalue = nlp_helper.cleanup_text(e['value'])  # value (ie name)\n",
    "                    rdfid = e['id']\n",
    "                    rdfid = filename.split(\".\")[0] + \"-\" + rdfid  # unique to each entity\n",
    "\n",
    "                    # test for geo (decide which type of obj to make - geo or non-geo)\n",
    "                    \n",
    "                    if 'geodetic' in e:\n",
    "\n",
    "                        if 'link-ref' in e:\n",
    "                            refrels = []\n",
    "                            linkdescs = []\n",
    "                            haslinks = True\n",
    "                            for k in e['link-ref']:  # every link-ref per entity\n",
    "                                refrels.append(k['idref'])  # keep these - all references  # noqa: E501\n",
    "                                if 'role-type' in k:  # test the role type is source  # noqa: E501\n",
    "                                    if k['role-type'] == \"source\":\n",
    "                                        linkdesc = rdfvalue + \" is a \" + k['role'] + \" in \" + k['entity-arg'][0]['value']  # noqa: E501\n",
    "                                        linkdescs.append(linkdesc)\n",
    "                                    else:\n",
    "                                        linkdescs.append(\"This item has parent links but no children\")  # noqa: E501\n",
    "                        else:\n",
    "                            haslinks = False\n",
    "                            \n",
    "                        if 'entity-ref' in e:\n",
    "                            isGeo = False  # already plotted, relegate to rdfobj list  # noqa: E501\n",
    "                        else:\n",
    "                            lat = float(e['geodetic']['latitude'])\n",
    "                            longg = float(e['geodetic']['longitude'])\n",
    "                            isGeo = True\n",
    "                            \n",
    "                    else:\n",
    "                        isGeo = False\n",
    "                        \n",
    "                    # check for addresses\n",
    "                    if e['ontology'] == \"entity:address:mail\":\n",
    "                        address = e['value']\n",
    "                        # location = nof.geocode_address(address)  # returns x,y\n",
    "                        location = geocode_address(address)  # returns x,y\n",
    "                        isGeo = True\n",
    "                        # set lat long\n",
    "                        lat = location['y']\n",
    "                        longg = location['x']\n",
    "                        # check for links\n",
    "                        if 'link-ref' in e:\n",
    "                            refrels = []\n",
    "                            linkdescs = []\n",
    "                            haslinks = True\n",
    "                            for k in e['link-ref']:  # every link-ref per entity\n",
    "                                refrels.append(k['idref'])  # keep these - all references  # noqa: E501\n",
    "                                if 'role-type' in k:  # test the role type is source  # noqa: E501\n",
    "                                    if k['role-type'] == \"source\":\n",
    "                                        linkdesc = rdfvalue + \" is a \" + k['role'] + \" in \" + k['entity-arg'][0]['value']  # noqa: E501\n",
    "                                        linkdescs.append(linkdesc)\n",
    "                                    else:\n",
    "                                        linkdescs.append(\"This item has parent links but no children\")  # noqa: E501\n",
    "                    else:\n",
    "                        haslinks = False\n",
    "                        \n",
    "                    # set up head and tail\n",
    "                    if 'entity-mention' in e:\n",
    "                        em = e['entity-mention'][0]\n",
    "                        if 'head' in em:\n",
    "                            newhead = nlp_helper.get_head(bigstring, int(em['head']), numchars)\n",
    "                        if 'tail' in em:\n",
    "                            newtail = nlp_helper.get_tail(bigstring, int(em['tail']), numchars)\n",
    "                            \n",
    "                    else:\n",
    "                        em = None\n",
    "                        \n",
    "                    if isGeo:\n",
    "\n",
    "                        if haslinks:\n",
    "                            # add refrels to new obj\n",
    "                            rdfobj = nlp_helper.RDFitemGeo(rdfid, rdfvalue, longg, lat, uniquets, filename,  # noqa: E501\n",
    "                                        refrels)\n",
    "                            ld = str(linkdescs)\n",
    "                            if len(ld) > 255:\n",
    "                                ld = ld[:254]  # shorten long ones\n",
    "                            rdfobj.set_link_details(ld)\n",
    "                        else:\n",
    "                            rdfobj = nlp_helper.RDFitemGeo(rdfid, rdfvalue, longg, lat, uniquets, filename)  # noqa: E501\n",
    "                            rdfobj.set_link_details(\"No links for this point\")\n",
    "                            \n",
    "                        # set type for symbology\n",
    "                        rdfobj.set_type(\"placename\")  # default\n",
    "                        rdfobj.set_subtype(\"unknown\")  # default\n",
    "                        if e['ontology'] == \"entity:place:city\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"city\")\n",
    "                        if e['ontology'] == \"entity:place:country\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"country\")\n",
    "                        if e['ontology'] == \"entity:place:province\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"province\")\n",
    "                        if e['ontology'] == \"entity:place:continent\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"continent\")\n",
    "                        if e['ontology'] == \"entity:numeric:coordinate:mgrs\":\n",
    "                            rdfobj.set_type(\"coordinate\")\n",
    "                            rdfobj.set_subtype(\"MGRS\")\n",
    "                        if e['ontology'] == \"entity:numeric:coordinate:latlong\":  # noqa: E501\n",
    "                            rdfobj.set_type(\"coordinate\")\n",
    "                            rdfobj.set_subtype(\"latlong\")\n",
    "                        if e['ontology'] == \"entity:address:mail\":\n",
    "                            rdfobj.set_type(\"address\")\n",
    "                            rdfobj.set_subtype(\"mail\")\n",
    "                        if e['ontology'] == \"entity:place:other\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"descriptor\")\n",
    "                        if e['ontology'] == \"entity:place:landform\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"landform\")\n",
    "                        if e['ontology'] == \"entity:organization:facility\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"facility\")\n",
    "                        if e['ontology'] == \"entity:place:water\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"water\")\n",
    "                        if e['ontology'] == \"entity:place:county\":\n",
    "                            rdfobj.set_type(\"placename\")\n",
    "                            rdfobj.set_subtype(\"county\")\n",
    "\n",
    "                        rdfobj.set_head(newhead)\n",
    "                        rdfobj.set_tail(newtail)\n",
    "                        item = rdfobj.toJSON()\n",
    "                        cosmos_item = client.CreateItem(container['_self'],{\n",
    "                                \"head\": rdfobj.head,\n",
    "                                \"id\": rdfobj.id,\n",
    "                                \"lat\": rdfobj.lat,\n",
    "                                \"linkdetails\": rdfobj.linkdetails,\n",
    "                                \"links\": rdfobj.links,\n",
    "                                \"long\": rdfobj.long,\n",
    "                                \"orgdoc\": rdfobj.orgdoc,\n",
    "                                \"subtype\": rdfobj.subtype,\n",
    "                                \"tail\": rdfobj.tail,\n",
    "                                \"timest\": rdfobj.timest,\n",
    "                                \"type\": rdfobj.type,\n",
    "                                \"value\": rdfobj.value\n",
    "                        })\n",
    "                        \n",
    "                        rdfobjsGeo.append(rdfobj)\n",
    "                        \n",
    "                        nlp_helper.post_to_geoevent(item, geoevent_url)\n",
    "                        \n",
    "                    else:  # not geo\n",
    "                        ontology = e['ontology']\n",
    "                        if haslinks:\n",
    "                            rdfobj = nlp_helper.RDFitem(rdfid, rdfvalue, uniquets, filename, ontology, refrels)  # noqa: E501\n",
    "                        else:  # has neither links nor address\n",
    "                            rdfobj = nlp_helper.RDFitem(rdfid, rdfvalue, uniquets, filename, ontology)\n",
    "\n",
    "                            rdfobj.set_head(newhead)\n",
    "                            rdfobj.set_tail(newtail)\n",
    "                            \n",
    "                            cosmos_item = client.CreateItem(container['_self'],{\n",
    "                                    \"value\": rdfobj.value,\n",
    "                                    \"links\": rdfobj.links,\n",
    "                                    \"orgdoc\": rdfobj.orgdoc, \n",
    "                                    \"id\": rdfobj.id, \n",
    "                                    \"type\": rdfobj.type,\n",
    "                                    \"head\": rdfobj.head,\n",
    "                                    \"tail\": rdfobj.tail\n",
    "                            })\n",
    "\n",
    "                            rdfobjs.append(rdfobj)\n",
    "                \n",
    "                if 'link' in doc:\n",
    "                    linksys = (doc['link'])\n",
    "                    for l in linksys:\n",
    "                        linkid = filename.split(\".\")[0] + \"-\" + l['id']\n",
    "                        if 'entity-arg' in l:\n",
    "                            fromid = filename.split(\".\")[0] + \"-\" + l['entity-arg'][0]['idref']\n",
    "                            toid = filename.split(\".\")[0] + \"-\" + l['entity-arg'][1]['idref']\n",
    "                            fromvalue = l['entity-arg'][0]['value']\n",
    "                            tovalue = l['entity-arg'][1]['value']\n",
    "                            fromrole = l['entity-arg'][0]['role']\n",
    "                            torole = l['entity-arg'][1]['role']\n",
    "                            fromroletype = l['entity-arg'][0]['role-type']\n",
    "                            toroletype = l['entity-arg'][1]['role-type']\n",
    "                        # build link objects\n",
    "                        linkobj = nlp_helper.RDFlinkItem(linkid, fromid, toid, fromvalue, tovalue,\n",
    "                                      fromrole, torole, fromroletype,\n",
    "                                      toroletype, uniquets)\n",
    "                        \n",
    "                        cosmos_link_item = client.CreateItem(link_container['_self'],{\n",
    "                                \"linkid\": linkobj.linkid,\n",
    "                                \"fromid\": linkobj.fromid,\n",
    "                                \"toid\": linkobj.toid,\n",
    "                                \"fromvalue\":linkobj.fromvalue,\n",
    "                                \"tovalue\":linkobj.tovalue,\n",
    "                                \"fromrole\":linkobj.fromrole,\n",
    "                                \"torole\": linkobj.torole,\n",
    "                                \"fromroletype\": linkobj.fromroletype,\n",
    "                                \"toroletype\": linkobj.toroletype\n",
    "                        })\n",
    "                        \n",
    "                        linkobjs.append(linkobj)\n",
    "                        \n",
    "                        _gremlin_insert_vertices = [\"g.addV('{0}').property('type', '{1}').property('id', '{0}')\".format(fromvalue, fromroletype),\n",
    "                        \"g.addV('{0}').property('type', '{1}').property('id', '{0}')\".format(tovalue, toroletype)]\n",
    "                        \n",
    "                        _gremlin_insert_edges = [\"g.V('{0}').addE('linked').to(g.V('{1}'))\".format(fromvalue, tovalue)]\n",
    "                        \n",
    "                        #try:\n",
    "                            #nlp_helper.insert_vertices(_gremlin_insert_vertices, graph_client)\n",
    "                        #except:\n",
    "                            #print('Error on node insertion')\n",
    "                        \n",
    "                        #nlp_helper.insert_edges(_gremlin_insert_edges, graph_client)\n",
    "                        \n",
    "                    \n",
    "                if 'event' in doc:\n",
    "                    events = doc['event']\n",
    "                    for e in events:\n",
    "                        evid = e['id']\n",
    "                        evvalue = e['value']\n",
    "                        if 'entity-arg' in e:\n",
    "                            fromid = filename.split(\".\")[0] + \"-\" + e['entity-arg'][0]['idref']\n",
    "                            fromvalue = e['entity-arg'][0]['value']\n",
    "                            fromrole = e['entity-arg'][0]['role']\n",
    "                            if len(e['entity-arg']) > 1:\n",
    "                                toid = filename.split(\".\")[0] + \"-\" + e['entity-arg'][1]['idref']\n",
    "                                tovalue = e['entity-arg'][1]['value']\n",
    "                                torole = e['entity-arg'][1]['role']\n",
    "                            else:\n",
    "                                toid = None\n",
    "                                tovalue = None\n",
    "                                torole = None\n",
    "                                \n",
    "    \n",
    "                        eventobj = nlp_helper.RDFeventItem(evvalue, evid, fromid, toid,\n",
    "                                        fromvalue, tovalue, fromrole,\n",
    "                                        torole, filename, uniquets)\n",
    "        \n",
    "                        cosmos_event_item = client.CreateItem(event_container['_self'],{\n",
    "                                    \"eventvalue\": eventobj.eventvalue,\n",
    "                                    \"eventid\": eventobj.eventid,\n",
    "                                    \"fromid\": eventobj.fromid,\n",
    "                                    \"toid\": eventobj.toid,\n",
    "                                    \"fromvalue\": eventobj.fromvalue,\n",
    "                                    \"tovalue\": eventobj.tovalue,\n",
    "                                    \"fromrole\": eventobj.fromrole,\n",
    "                                    \"torole\": eventobj.torole,\n",
    "                                    \"orgdoc\": eventobj.orgdoc\n",
    "                        })\n",
    "        \n",
    "                        eventobjs.append(eventobj)\n",
    "            \n",
    "                        _gremlin_insert_vertices = [\"g.addV('{0}').property('type', '{1}').property('id', '{0}')\".format(fromvalue, fromroletype),\n",
    "                        \"g.addV('{0}').property('type', '{1}').property('id', '{0}')\".format(tovalue, toroletype)]\n",
    "                        \n",
    "                        _gremlin_insert_edges = [\"g.V('{0}').addE('{1}').to(g.V('{2}'))\".format(fromvalue, fromrole, tovalue)]\n",
    "                        \n",
    "                        #try:\n",
    "                            #nlp_helper.insert_vertices(_gremlin_insert_vertices, graph_client)\n",
    "                        #except:\n",
    "                            #print('Error on node insertion')\n",
    "                        \n",
    "                        #nlp_helper.insert_edges(_gremlin_insert_edges, graph_client)\n",
    "                            \n",
    "            end = time.time()\n",
    "            process_time = end - start\n",
    "            print(\"Non-Geospatial Entities Found: \" + str(len(rdfobjs)))\n",
    "            print(\"Geospatial Entities Found: \" + str(len(rdfobjsGeo)))\n",
    "            print(\"Links Found: \" + str(len(linkobjs)))\n",
    "            print(\"Events Found: \" + str(len(eventobjs)))\n",
    "            print(\"Process took {0} seconds\".format(str(process_time)))\n",
    "            count +=1\n",
    "            \n",
    "    if count > 4:\n",
    "        print(\"Exiting\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
